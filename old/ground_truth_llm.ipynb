{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bbba9aa-263f-4b08-aa07-87edecc9ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f806a-f5d6-4547-ba91-35075a477a50",
   "metadata": {},
   "source": [
    "#### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a21c1bc8-bfa7-4cfb-87f1-f5065244f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-5-nano\"\n",
    "QUESTIONS_PER_DOC = 2 # development-stage\n",
    "\n",
    "OUTPUT_PATH = Path(\"../data/eval/ground_truth_gpt5nano.json\")\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5ba56-166d-47ef-a75a-ff2a0531fba7",
   "metadata": {},
   "source": [
    "## Initialise OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77621d1-dcb8-4ef0-96bf-941cdce69055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_KEY entered\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "try:\n",
    "    API_KEY = getpass.getpass()\n",
    "except Exception as error:\n",
    "    print('ERROR', error)\n",
    "else:\n",
    "    print('API_KEY entered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253d518b-884f-4821-94f6-bdf5f1f35bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d798e667-cdee-4547-be6a-a64a72a312f4",
   "metadata": {},
   "source": [
    "## Load documents\n",
    "(canonical source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e47aef2f-42b3-4aa7-ac69-1d852f8424b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/canonical/all_documents.json\") as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f399199f-c712-4e3b-b2e1-28a7e4d117f4",
   "metadata": {},
   "source": [
    "## Prompt to generate questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ef6d81-e925-4748-a9ec-37084d8eb06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_question_prompt(text, n_questions):\n",
    "    return f\"\"\"\n",
    "You are generating user search questions for a retrieval evaluation dataset.\n",
    "\n",
    "The user has NOT seen the text below.\n",
    "They are searching for information contained in it.\n",
    "\n",
    "Generate {n_questions} DISTINCT, realistic user questions that could retrieve this text.\n",
    "- Questions should vary in wording and intent\n",
    "- Do NOT quote the text\n",
    "- Do NOT include answers\n",
    "- Do NOT number the questions\n",
    "- Each question must be on a separate line\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58e17c1-ce6c-46b7-aed2-c1fd43a761b4",
   "metadata": {},
   "source": [
    "## Function to call GPT-5-nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8e5687b-aa97-4cb4-84b7-70c98f52c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(text, n_questions=5):\n",
    "    response = client.responses.create(\n",
    "        model=MODEL_NAME,\n",
    "        input=build_question_prompt(text, n_questions)\n",
    "    )\n",
    "\n",
    "    raw = response.output_text.strip()\n",
    "    questions = [q.strip(\"- \").strip() for q in raw.split(\"\\n\") if q.strip()]\n",
    "    \n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d59c3c4-6bff-4ac7-a700-7d87a76d7094",
   "metadata": {},
   "source": [
    "## Generate ground truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10d0a748-58e7-488a-b592-2d93793ec59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:42<00:00,  8.53s/it]\n"
     ]
    }
   ],
   "source": [
    "ground_truth = []\n",
    "\n",
    "for doc in tqdm(documents[:5]):  # start SMALL (e.g. 20-50 docs); SCALE later\n",
    "    doc_id = doc[\"id\"]\n",
    "    text = doc[\"text\"]\n",
    "\n",
    "    try:\n",
    "        questions = generate_questions(text, QUESTIONS_PER_DOC)\n",
    "\n",
    "        for q in questions:\n",
    "            ground_truth.append({\n",
    "                \"query\": q,\n",
    "                \"relevant_doc_ids\": [doc_id]\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error for doc {doc_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e559f00b-267b-44ae-b154-dcc4d4c86d17",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0889016-4760-42e1-9769-5c3115cf083c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': \"What topics were covered in Google's I/O session about the AI stack for developers, including foundation models and frameworks?\",\n",
       "  'relevant_doc_ids': ['4TE-KFXvhAk__chunk_000']},\n",
       " {'query': \"Who were the presenters discussing Google's AI stack at Google I/O, and what are their roles?\",\n",
       "  'relevant_doc_ids': ['4TE-KFXvhAk__chunk_000']},\n",
       " {'query': 'How does Google describe the evolution of its AI stack from TensorFlow to Gemini, and what is meant by the Gemini era?',\n",
       "  'relevant_doc_ids': ['4TE-KFXvhAk__chunk_000']},\n",
       " {'query': 'Which AI frameworks does Google highlight for researchers and developers, such as JAX, Keras, and PyTorch, in their session?',\n",
       "  'relevant_doc_ids': ['4TE-KFXvhAk__chunk_000']},\n",
       " {'query': 'What does Google say about infrastructure and software focus in their AI talk, and what is the emphasis on real-world applications?',\n",
       "  'relevant_doc_ids': ['4TE-KFXvhAk__chunk_000']}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3d921c4-ec92-441a-bea0-5115bd3d53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids=[]\n",
    "for i in range(0, len(ground_truth)):\n",
    "    doc_id = ground_truth[i][\"relevant_doc_ids\"][0]\n",
    "    doc_ids.append(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ceac187a-a1b4-453d-a31f-3179c18c03ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4TE-KFXvhAk__chunk_000',\n",
       " '4TE-KFXvhAk__chunk_001',\n",
       " '4TE-KFXvhAk__chunk_002',\n",
       " '4TE-KFXvhAk__chunk_003',\n",
       " '4TE-KFXvhAk__chunk_004'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed20af81-a786-4ee8-ac78-4631eee38d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4TE-KFXvhAk__chunk_000',\n",
       " '4TE-KFXvhAk__chunk_000',\n",
       " '4TE-KFXvhAk__chunk_000',\n",
       " '4TE-KFXvhAk__chunk_000',\n",
       " '4TE-KFXvhAk__chunk_000',\n",
       " '4TE-KFXvhAk__chunk_001',\n",
       " '4TE-KFXvhAk__chunk_001',\n",
       " '4TE-KFXvhAk__chunk_001',\n",
       " '4TE-KFXvhAk__chunk_001',\n",
       " '4TE-KFXvhAk__chunk_001',\n",
       " '4TE-KFXvhAk__chunk_002',\n",
       " '4TE-KFXvhAk__chunk_002',\n",
       " '4TE-KFXvhAk__chunk_002',\n",
       " '4TE-KFXvhAk__chunk_002',\n",
       " '4TE-KFXvhAk__chunk_002',\n",
       " '4TE-KFXvhAk__chunk_003',\n",
       " '4TE-KFXvhAk__chunk_003',\n",
       " '4TE-KFXvhAk__chunk_003',\n",
       " '4TE-KFXvhAk__chunk_003',\n",
       " '4TE-KFXvhAk__chunk_003',\n",
       " '4TE-KFXvhAk__chunk_004',\n",
       " '4TE-KFXvhAk__chunk_004',\n",
       " '4TE-KFXvhAk__chunk_004',\n",
       " '4TE-KFXvhAk__chunk_004',\n",
       " '4TE-KFXvhAk__chunk_004']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f7468d8-3e23-4c4b-874b-b5baca34a415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d1a9a1-e0cb-4695-8336-95f8a209d0f7",
   "metadata": {},
   "source": [
    "## Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee6c7d-7e95-462c-a1d2-e237f1762506",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_PATH, \"w\") as f:\n",
    "    json.dump(ground_truth, f, indent=2)\n",
    "\n",
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d2513-992c-4971-b7d6-f1a5ea10ebb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
