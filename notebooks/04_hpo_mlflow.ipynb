{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7fd326-5903-4fdd-be8c-8613fdd04667",
   "metadata": {},
   "source": [
    "# Set up and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68674458-6bcf-4994-b863-2e38c84458a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/al/Documents/rag-google-io\n"
     ]
    }
   ],
   "source": [
    "# Add project root to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c26172c0-44d8-4b0d-8e4a-b74d316560cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.optuna\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from retrieval.rerankers.cross_encoder import CrossEncoderReranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddc57cf7-329f-42e9-a0e4-643e26f1489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval.evaluation.pipelines import (\n",
    "    dense_retrieve,\n",
    "    evaluate_reranking,\n",
    ")\n",
    "\n",
    "from retrieval.rerankers.cross_encoder import CrossEncoderReranker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038963d3-b5d8-45c8-89da-df72421ab8c7",
   "metadata": {},
   "source": [
    "# MLflow Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d96123f-bac3-48fc-b0a9-6d66a9afefc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/al/Documents/rag-google-io/notebooks/../mlruns/624004126080311294', creation_time=1769018106611, experiment_id='624004126080311294', last_update_time=1769018106611, lifecycle_stage='active', name='dense_rerank_hpo', tags={}>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"file:../mlruns\")\n",
    "mlflow.set_experiment(\"dense_rerank_hpo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4036f53e-a139-474b-bd75-df152aa35959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:../mlruns'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_tracking_uri() #check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ae523-2036-48c5-8ad4-c87e6594112d",
   "metadata": {},
   "source": [
    "# Load Data & Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2ef8c43-42c1-4fc8-9712-ca5597647ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 evaluation queries\n"
     ]
    }
   ],
   "source": [
    "# Load ground truth\n",
    "with open(\"../data/eval/ground_truth_gpt5nano.json\", \"r\") as f:\n",
    "    ground_truth = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(ground_truth)} evaluation queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a77ad88-97cc-4574-9293-a35f02b1d147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='sparse_collection'), CollectionDescription(name='google-io-transcripts'), CollectionDescription(name='hybrid_collection')]\n"
     ]
    }
   ],
   "source": [
    "# Qdrant\n",
    "q_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "q_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "print(q_client.get_collections()) #check\n",
    "COLLECTION = \"hybrid_collection\"\n",
    "\n",
    "# Embedding model (fixed for HPO)\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed_query(text: str):\n",
    "    return embedding_model.encode(text).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cbdc77-ede7-455a-893f-591bc974ab5c",
   "metadata": {},
   "source": [
    "# Evaluation Wrapper (Key for HPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc951f83-3daf-4bcd-9605-8afa01829bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_config(\n",
    "    retrieve_k: int,\n",
    "    rerank_k: int,\n",
    "    rerank_model: str,\n",
    "):\n",
    "    reranker = CrossEncoderReranker(rerank_model)\n",
    "\n",
    "    recalls = []\n",
    "    mrrs = []\n",
    "    latencies = []\n",
    "\n",
    "    for item in ground_truth:\n",
    "        start = time.time()\n",
    "\n",
    "        results = retrieve_and_rerank(\n",
    "            query=item[\"query\"],\n",
    "            retrieve_k=retrieve_k,\n",
    "            rerank_k=rerank_k,\n",
    "            reranker=reranker,\n",
    "        )\n",
    "\n",
    "        latencies.append(time.time() - start)\n",
    "\n",
    "        relevant_ids = item[\"relevant_doc_ids\"]\n",
    "        recalls.append(recall_at_k(results, relevant_ids, 5))\n",
    "        mrrs.append(mrr(results, relevant_ids))\n",
    "\n",
    "    return {\n",
    "        \"recall@5\": float(np.mean(recalls)),\n",
    "        \"mrr\": float(np.mean(mrrs)),\n",
    "        \"latency_avg\": float(np.mean(latencies)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed94da-0141-4c90-b754-7b7318b24458",
   "metadata": {},
   "source": [
    "# Optuna Objective (with MLflow logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "255f55fd-f5ca-4ad7-a767-df31c9a40ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    retrieve_k = trial.suggest_categorical(\"retrieve_k\", [20, 30, 50, 75, 100])\n",
    "    rerank_k = trial.suggest_categorical(\"rerank_k\", [5, 10])\n",
    "    rerank_model = trial.suggest_categorical(\n",
    "        \"rerank_model\",\n",
    "        [\n",
    "            \"cross-encoder/ms-marco-TinyBERT-L-2-v2\",\n",
    "            \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "            \"BAAI/bge-reranker-base\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    reranker = CrossEncoderReranker(rerank_model)\n",
    "\n",
    "    metrics = evaluate_reranking(\n",
    "        ground_truth=ground_truth,\n",
    "        retrieve_fn=lambda q, k: dense_retrieve(\n",
    "            q_client, embed_query, COLLECTION, q, k\n",
    "        ),\n",
    "        reranker=reranker,\n",
    "        retrieve_k=retrieve_k,\n",
    "        rerank_k=rerank_k,\n",
    "    )\n",
    "\n",
    "    cost_penalty = (retrieve_k / 100) * 0.1\n",
    "    return metrics[\"recall@5\"] - cost_penalty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af630b2e-d0ab-46e1-929f-63e9c38e44e5",
   "metadata": {},
   "source": [
    "# Run the Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b65635e-7d9b-4543-a054-8aadf078f8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:07:07,770]\u001b[0m A new study created in memory with name: dense_rerank_hpo\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:07:25,153]\u001b[0m Trial 0 finished with value: 0.88 and parameters: {'retrieve_k': 20, 'rerank_k': 5, 'rerank_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2'}. Best is trial 0 with value: 0.88.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: BAAI/bge-reranker-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8779f1e45d45f58817f42c19bd3419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/799 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7228ec011143b98e6d35b6d4696556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5fc303ddbc4569a77cc0ba326d8bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ef990f4cf7466b92d8b06afd2ef136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33749ea6eb5446bbf36c47b7c7d72d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c2598336bd4365a9b7c861cf17d56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190de863992d4bf1bc383665f3068dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:09:48,304]\u001b[0m Trial 1 finished with value: 0.97 and parameters: {'retrieve_k': 30, 'rerank_k': 10, 'rerank_model': 'BAAI/bge-reranker-base'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: cross-encoder/ms-marco-TinyBERT-L-2-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:09:57,467]\u001b[0m Trial 2 finished with value: 0.9 and parameters: {'retrieve_k': 100, 'rerank_k': 5, 'rerank_model': 'cross-encoder/ms-marco-TinyBERT-L-2-v2'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: BAAI/bge-reranker-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:16:00,438]\u001b[0m Trial 3 finished with value: 0.9 and parameters: {'retrieve_k': 100, 'rerank_k': 5, 'rerank_model': 'BAAI/bge-reranker-base'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:16:21,759]\u001b[0m Trial 4 finished with value: 0.97 and parameters: {'retrieve_k': 30, 'rerank_k': 5, 'rerank_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:16:40,405]\u001b[0m Trial 5 finished with value: 0.97 and parameters: {'retrieve_k': 30, 'rerank_k': 10, 'rerank_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: BAAI/bge-reranker-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:17:51,957]\u001b[0m Trial 6 finished with value: 0.88 and parameters: {'retrieve_k': 20, 'rerank_k': 5, 'rerank_model': 'BAAI/bge-reranker-base'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: cross-encoder/ms-marco-TinyBERT-L-2-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:17:58,590]\u001b[0m Trial 7 finished with value: 0.9 and parameters: {'retrieve_k': 100, 'rerank_k': 10, 'rerank_model': 'cross-encoder/ms-marco-TinyBERT-L-2-v2'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: cross-encoder/ms-marco-TinyBERT-L-2-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:18:01,651]\u001b[0m Trial 8 finished with value: 0.97 and parameters: {'retrieve_k': 30, 'rerank_k': 10, 'rerank_model': 'cross-encoder/ms-marco-TinyBERT-L-2-v2'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: BAAI/bge-reranker-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:25:55,409]\u001b[0m Trial 9 finished with value: 0.925 and parameters: {'retrieve_k': 75, 'rerank_k': 10, 'rerank_model': 'BAAI/bge-reranker-base'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: BAAI/bge-reranker-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:31:18,472]\u001b[0m Trial 10 finished with value: 0.95 and parameters: {'retrieve_k': 50, 'rerank_k': 10, 'rerank_model': 'BAAI/bge-reranker-base'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:31:37,620]\u001b[0m Trial 11 finished with value: 0.97 and parameters: {'retrieve_k': 30, 'rerank_k': 5, 'rerank_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:31:56,377]\u001b[0m Trial 12 finished with value: 0.97 and parameters: {'retrieve_k': 30, 'rerank_k': 5, 'rerank_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: BAAI/bge-reranker-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:33:43,414]\u001b[0m Trial 13 finished with value: 0.97 and parameters: {'retrieve_k': 30, 'rerank_k': 10, 'rerank_model': 'BAAI/bge-reranker-base'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:34:13,647]\u001b[0m Trial 14 finished with value: 0.95 and parameters: {'retrieve_k': 50, 'rerank_k': 10, 'rerank_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: BAAI/bge-reranker-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:38:38,920]\u001b[0m Trial 15 finished with value: 0.925 and parameters: {'retrieve_k': 75, 'rerank_k': 5, 'rerank_model': 'BAAI/bge-reranker-base'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:38:57,529]\u001b[0m Trial 16 finished with value: 0.97 and parameters: {'retrieve_k': 30, 'rerank_k': 5, 'rerank_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: BAAI/bge-reranker-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:40:42,963]\u001b[0m Trial 17 finished with value: 0.97 and parameters: {'retrieve_k': 30, 'rerank_k': 10, 'rerank_model': 'BAAI/bge-reranker-base'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:41:01,417]\u001b[0m Trial 18 finished with value: 0.97 and parameters: {'retrieve_k': 30, 'rerank_k': 10, 'rerank_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reranker model: cross-encoder/ms-marco-TinyBERT-L-2-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-21 18:41:05,376]\u001b[0m Trial 19 finished with value: 0.95 and parameters: {'retrieve_k': 50, 'rerank_k': 5, 'rerank_model': 'cross-encoder/ms-marco-TinyBERT-L-2-v2'}. Best is trial 1 with value: 0.97.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"dense_rerank_hpo\",\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c1e66d-66f7-4c68-8cb3-383bee867659",
   "metadata": {},
   "source": [
    "# Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d51fe044-b8f1-42ca-bb47-f3c83456848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.97\n",
      "  Params:\n",
      "    retrieve_k: 30\n",
      "    rerank_k: 10\n",
      "    rerank_model: BAAI/bge-reranker-base\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value:\", trial.value)\n",
    "print(\"  Params:\")\n",
    "for k, v in trial.params.items():\n",
    "    print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3a902-1034-468f-9afa-73df48285474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af32582-b5e6-4a88-b283-f4a47a3f61be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff46b5c-d808-4889-9efa-0b8327ffa3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef41fb-007f-4669-8bdf-a2f54e3643e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88af706-c367-494d-bbd1-ce7729024f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
