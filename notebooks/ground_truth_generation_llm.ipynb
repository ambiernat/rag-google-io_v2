{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth Generation for Retrieval Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timezone\n",
    "import getpass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-5-nano\"\n",
    "QUESTIONS_PER_DOC = 2  # dev-stage\n",
    "NUM_DOCS = 5           # number of canonical docs to process (dev vs full run)\n",
    "# Timestamped output to avoid overwriting\n",
    "timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%S\")\n",
    "OUTPUT_PATH = Path(f\"../data/eval/ground_truth_gpt5nano_{timestamp}.json\")\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "CANONICAL_PATH = Path(\"../data/canonical/all_documents.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise OpenAI client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_KEY entered\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    API_KEY = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "except Exception as error:\n",
    "    print(\"ERROR\", error)\n",
    "else:\n",
    "    print(\"API_KEY entered\")\n",
    "    \n",
    "client = OpenAI(api_key=API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load canonical documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 99 canonical documents.\n"
     ]
    }
   ],
   "source": [
    "with open(CANONICAL_PATH) as f:\n",
    "    documents = json.load(f)\n",
    "    print(f\"Loaded {len(documents)} canonical documents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt to generate questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_question_prompt(text, n_questions):\n",
    "    return f\"\"\"You are generating user search questions for a retrieval evaluation dataset.\n",
    "\n",
    "The user has NOT seen the text below.\n",
    "They are searching for information contained in it.\n",
    "\n",
    "Generate {n_questions} DISTINCT, realistic user questions that could retrieve this text.\n",
    "- Questions should vary in wording and intent\n",
    "- Do NOT quote the text\n",
    "- Do NOT include answers\n",
    "- Do NOT number the questions\n",
    "- Each question must be on a separate line\n",
    "\n",
    "TEXT:\n",
    "{text}\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to call GPT-5-nano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_questions(text, n_questions=5):\n",
    "#     response = client.responses.create(\n",
    "#         model=MODEL_NAME,\n",
    "#         input=build_question_prompt(text, n_questions),\n",
    "#         max_output_tokens=256\n",
    "#     )\n",
    "#     raw = response.output_text.strip()\n",
    "    \n",
    "#     # Deterministic: sorted set of unique questions\n",
    "#     questions = sorted(set(\n",
    "#         q.strip(\" -\\n\\r\\t\")\n",
    "#         for q in raw.split(\"\\n\")\n",
    "#         if q.strip()\n",
    "#     ))\n",
    "    \n",
    "#     return questions\n",
    "\n",
    "\n",
    "\n",
    "# def generate_questions(text, n_questions=5):\n",
    "#     response = client.responses.create(\n",
    "#         model=MODEL_NAME,\n",
    "#         input=build_question_prompt(text, n_questions),\n",
    "#         max_output_tokens=256,\n",
    "#         reasoning={\"effort\": \"minimal\"}\n",
    "#     )\n",
    "    \n",
    "#     # Navigate the response structure: output -> message item -> content -> text\n",
    "#     raw = \"\"\n",
    "#     for item in response.output:\n",
    "#         if item.type == 'message' and item.content:\n",
    "#             for content_item in item.content:\n",
    "#                 if content_item.type == 'output_text':\n",
    "#                     raw += content_item.text\n",
    "    \n",
    "#     questions = [q.strip(\"- \").strip() for q in raw.strip().split(\"\\n\") if q.strip()]\n",
    "#     return questions\n",
    "\n",
    "\n",
    "def generate_questions(text, n_questions=5):\n",
    "    response = client.responses.create(\n",
    "        model=MODEL_NAME,\n",
    "        input=build_question_prompt(text, n_questions),\n",
    "        max_output_tokens=256,\n",
    "        reasoning={\"effort\": \"minimal\"}\n",
    "    )\n",
    "    \n",
    "    # Navigate the response structure: output -> message item -> content -> text\n",
    "    raw = \"\"\n",
    "    for item in response.output:\n",
    "        if item.type == 'message' and item.content:\n",
    "            for content_item in item.content:\n",
    "                if content_item.type == 'output_text':\n",
    "                    raw += content_item.text\n",
    "    \n",
    "    # Deterministic: sorted set of unique questions\n",
    "    questions = sorted(set(\n",
    "        q.strip(\"- \").strip()\n",
    "        for q in raw.strip().split(\"\\n\")\n",
    "        if q.strip()\n",
    "    ))\n",
    "    \n",
    "    return questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ground truth dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "ground_truth = []\n",
    "for doc in tqdm(documents[:NUM_DOCS]):\n",
    "    doc_id = doc[\"id\"]\n",
    "    text = doc[\"text\"]\n",
    "    try:\n",
    "        questions = generate_questions(text, QUESTIONS_PER_DOC)\n",
    "        \n",
    "        # Changed: only warn if we got ZERO questions, not just fewer than expected\n",
    "        if len(questions) == 0:\n",
    "            print(f\"[WARNING] No questions generated for {doc_id}\")\n",
    "            continue  # Skip this document\n",
    "        \n",
    "        # Log if we got fewer than expected (informational, not a warning)\n",
    "        if len(questions) < QUESTIONS_PER_DOC:\n",
    "            print(f\"[INFO] Generated {len(questions)}/{QUESTIONS_PER_DOC} unique questions for {doc_id}\")\n",
    "        \n",
    "        for q in questions:\n",
    "            ground_truth.append({\n",
    "                \"query\": q,\n",
    "                \"relevant_doc_ids\": [doc_id]\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Doc {doc_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 10 questions.\n",
      "Questions cover 5 documents: {'gHHjDRDNUNU__chunk_002', 'gHHjDRDNUNU__chunk_000', 'gHHjDRDNUNU__chunk_001', 'gHHjDRDNUNU__chunk_003', 'gHHjDRDNUNU__chunk_004'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nGenerated {len(ground_truth)} questions.\")\n",
    "unique_doc_ids = set(gt[\"relevant_doc_ids\"][0] for gt in ground_truth)\n",
    "print(f\"Questions cover {len(unique_doc_ids)} documents: {unique_doc_ids}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth saved to ../data/eval/ground_truth_gpt5nano_20260122T203300.json\n"
     ]
    }
   ],
   "source": [
    "with open(OUTPUT_PATH, \"w\") as f:\n",
    "    json.dump(ground_truth, f, indent=2)\n",
    "    \n",
    "print(f\"Ground truth saved to {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
