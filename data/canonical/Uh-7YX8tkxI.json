[
  {
    "id": "Uh-7YX8tkxI__chunk_000",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 0.0,
    "timestamp_end": 124.52999999999999,
    "text": "[MUSIC PLAYING] ALEX KANTROWITZ: All\nright, everybody, we have an amazing\ncrowd here today. We're going to be\nlive-streaming this. So let's hear you make\nsome noise so everybody can hear that you're here. Let's go. [CHEERING] Not bad. I'm Alex Kantrowitz I'm the host\nof \"Big Technology\" podcast, and I'm here to speak with you\nabout the frontiers of AI with two amazing guests. Demis Hassabis, the CEO\nof DeepMind, is here. Google DeepMind. Good to see you, Demis. DEMIS HASSABIS:\nGood to see you too. ALEX KANTROWITZ: And we\nhave a special guest. Sergey Brin, the co-founder\nof Google, is also here. [CHEERS, APPLAUSE] All right. So this is going to be fun. Let's start with\nthe frontier models. Demis, this is for you. With what we know today\nabout frontier models, how much improvement is\nthere left to be unlocked, and why do you think so\nmany smart people are saying that the gains\nare about to level off? DEMIS HASSABIS: I think we're\nseeing incredible progress. You've all seen it today, all\nthe amazing stuff we showed in the [INAUDIBLE] keynote. So I think we're\nseeing incredible gains with the existing techniques,\npushing them to the limit. But we're also inventing new\nthings all the time as well. And I think to get all\nthe way to something like AGI may require one or\ntwo more new breakthroughs. And I think we have\nlots of promising ideas that we're cooking\nup and we hope to bring into the main\nbranch of the Gemini branch. ALEX KANTROWITZ: All right. And so there's been this\ndiscussion about scale. Does solve all problems,\nor does it not? So I want to ask you, in terms\nof the improvement that's available today, is\nscale still the star, or is it a supporting actor? DEMIS HASSABIS: I think I've\nalways been of the opinion that you need both. You need to scale to the\nmaximum the techniques that you know about. You want to exploit them to\nthe limit, whether that's data or compute scale. And at the same time, you want\nto spend a bunch of effort on what's coming next maybe six\nmonths, a year down the line,",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_001",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 112.475,
    "timestamp_end": 235.85,
    "text": "that you know about. You want to exploit them to\nthe limit, whether that's data or compute scale. And at the same time, you want\nto spend a bunch of effort on what's coming next maybe six\nmonths, a year down the line, so you have the next innovation\nthat might do a 10x leap in some way to intersect with the scale. So you want both in my opinion. I don't know. Sergey, what do you think? SERGEY BRIN: I mean, I agree. It takes both. You can have algorithmic\nimprovements and simply compute improvements-- better chips,\nmore chips, more power, bigger data centers. I think that\nhistorically, if you look at things like\nthe n-body problem and simulating just\ngravitational bodies and things like that, as you plot it,\nthe algorithmic advances have actually beaten out the\ncomputational advances even with Moore's law. If I had to guess, I would say\nthe algorithmic advances are probably going to be\neven more significant than the computational advances. But both of them\nare coming up now, so we're getting the\nbenefits of both. ALEX KANTROWITZ:\nAnd Demis, do you think the majority\nof your improvement is coming from building\nbigger data centers and using more chips? There's talk about how the\nworld will be just wallpapered with data centers. Is that your vision? DEMIS HASSABIS: Well, no. Look, I mean, we're definitely\ngoing to need a lot more data centers. It's amazing that--\nit's still amazes me, from a scientific point\nof view, we turn sand into thinking machines. It's pretty incredible. But actually, it's not\njust for the training. Now we've got these models\nthat everyone wants to use. And actually, we're seeing\nincredible demand for 2.5 Pro. And I think Flash we're\nreally excited about how performant that is for the\nincredible sort of low cost. I think the whole world's going\nto want to use these things. And so we're going to need a\nlot of data centers for serving. And also for\ninference time compute You saw you saw\nDeepthink today-- 2.5 Pro Deepthink. The more time you give\nit, the better it will be.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_002",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 220.78,
    "timestamp_end": 330.92,
    "text": "I think the whole world's going\nto want to use these things. And so we're going to need a\nlot of data centers for serving. And also for\ninference time compute You saw you saw\nDeepthink today-- 2.5 Pro Deepthink. The more time you give\nit, the better it will be. And certain tasks, very high\nvalue, very difficult tasks, it will be worth letting it\nthink for a very long time. And we're thinking about how\nto push that even further. And again, that's going\nto require a lot of chips at runtime. ALEX KANTROWITZ: OK. So you brought up\ntest time compute. We've been about a year into\nthis reasoning paradigm, and you and I have\nspoken about it twice in the past as\nsomething that you might be able to add on to\ntraditional LLMs to get gains. So I think this is a pretty\ngood time for me to be like, \"What's happening?\" Can you help us contextualize\nthe magnitude of improvement we're seeing from reasoning? DEMIS HASSABIS:\nWell, we've always been big believers\nin what we're now calling this thinking paradigm. If you go back to our very early\nwork on things like AlphaGo and AlphaZero, our agent\nwork on playing games, they will all have this type\nof attribute of a thinking system on top of a model. And actually, you can\nquantify how much difference that makes if you look at\na game like chess or Go. We had versions of\nAlphaGo and AlphaZero with the thinking turned\noff that was just the model telling you its first idea. And it's not bad. It's maybe master level--\nsomething like that. But then, if you\nturn the thinking on, it'll be way beyond\nworld champion level. It's like a 600\nELO-plus difference between the two versions. So you can see that\nin games, let alone for the real world, which\nis way more complicated. And I think the gains\nwill be potentially even bigger by adding this thinking\ntype of paradigm on top. Of course, the challenge\nis that your models-- and I talked about this\nearlier in the talk-- need to be a kind\nof world model. And that's much harder\nthan building a model of a simple game of course.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_003",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 316.6,
    "timestamp_end": 445.65999999999997,
    "text": "bigger by adding this thinking\ntype of paradigm on top. Of course, the challenge\nis that your models-- and I talked about this\nearlier in the talk-- need to be a kind\nof world model. And that's much harder\nthan building a model of a simple game of course. And it has errors in it,\nand those can compound over longer term plans. But I think we're making\nreally good progress on all those fronts. SERGEY BRIN: Yeah, look,\nI mean, as Demis said, DeepMind really pioneered a lot\nof this reinforcement learning work. And what they did with AlphaGo\nand AlphaZero, as you mentioned, showed, as I recall, something\nyou would take 5,000 times as much training to match what\nyou were able to do with still a lot of training and the\ninference time compute that you were doing with Go. So it's obviously\na huge advantage. And obviously,\nlike most of us, we get some benefit by thinking\nbefore we speak, although-- ALEX KANTROWITZ: Not always. [LAUGHTER] SERGEY BRIN: I always\nget reminded to do that. But I think that\nthe AI's obviously are much stronger once\nyou add that capability. And I think we're just\nat the tip of the iceberg right now in that sense. It's been less than a year\nthan these models have really been around. DEMIS HASSABIS:\nEspecially if you think about, obviously with an\nAI, during its thinking process it can also use a bunch\nof tools or even other AIs during that thinking\nprocess to improve what the final output is. So I think it's going to be an\nincredibly powerful paradigm. ALEX KANTROWITZ: Deepthink\nis very interesting. I'm going to describe it-- I'm trying to describe it right. It's basically a bunch of\nparallel reasoning processes working and then\nchecking each other. And then it's like\nreasoning on steroids. Now, Demis, you mentioned that\nthe industry needs a couple more advances to get to AGI. Where would you put\nthis type of mechanism? Is this one of those that\nmight get the industry closer? DEMIS HASSABIS: I think so. I think it's maybe part\nof one, shall we say. And there are others\ntoo that we need",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_004",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 432.22,
    "timestamp_end": 550.7199999999999,
    "text": "Where would you put\nthis type of mechanism? Is this one of those that\nmight get the industry closer? DEMIS HASSABIS: I think so. I think it's maybe part\nof one, shall we say. And there are others\ntoo that we need to-- maybe this can be part\nof improving reasoning. Where does true\ninvention come from, where you're not just\nsolving a maths conjecture, you're actually proposing\none or hypothesizing a new theory in physics? I think we don't\nhave systems yet that can do that type of creativity. I think they are coming. And these types\nof paradigms might be helpful in\nthings like thinking and then probably\nmany other things. I mean, I think we\nneed a lot of advances on the accuracy of the world\nmodels that we're building. I think you saw that with\nVeo, the potential Veo 3. It amazes me how it\ncan intuit the physics of the light and the gravity. Having someone who-- I used to\nwork on computer games, not just the AI but also graphics\nengines in my early career, and remember having to\ndo all of this by hand, and program all of the\nlighting, and the shaders, and all of these things. Incredibly complicated stuff\nwe used to do in early games, And now it's just intuiting\nit within the model. It's pretty astounding. ALEX KANTROWITZ:\nI saw you shared an image of a frying pan with\nsome onions and some oil. [INTERPOSING VOICES] ALEX KANTROWITZ: There was no\nsubliminal messaging about that? DEMIS HASSABIS: Not really. Not really. Just maybe a subtle,\nsubtle message. ALEX KANTROWITZ: OK. So we said the word or the\nacronym AGI a couple of times. There's, I think, a movement\nwithin the AI world right now to say let's\nnot say AGI anymore. The term is so overused\nas to be meaningless. But Demis, it seems like\nyou think it's important. Why? DEMIS HASSABIS: Yeah, I\nthink it's very important. But I think maybe I need to\nwrite something about this also with Shane Legg, who's\nour chief scientist, who was one of the people who\ninvented the term 25 years back. I think there's two things\nthat are getting a little bit conflated.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_005",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 537.46,
    "timestamp_end": 648.49,
    "text": "But I think maybe I need to\nwrite something about this also with Shane Legg, who's\nour chief scientist, who was one of the people who\ninvented the term 25 years back. I think there's two things\nthat are getting a little bit conflated. One is, what can a typical\nperson do, an individual do? And we're all very\ncapable, but we can only do-- however capable\nyou are, there's only a certain slice of\nthings that one is expert in. Right? Or you could say, can you do\nwhat 90% of humans can do? That's obviously going to be\neconomically very important and I think from a product\nperspective also very important. So it's a very\nimportant milestone. So maybe we should say that's\ntypical human intelligence. But what I'm interested in,\nand what I would call AGI, is really a more\ntheoretical construct. Which is, what is\nthe human brain as an architecture able to do? And the human brain is an\nimportant reference point, because it's the only evidence\nwe have maybe in the universe that general\nintelligence is possible. And there, it would have\nto be able to-- you'd have to show your system\nwas capable of doing the range of things even\nthe best humans in history were able to do with the\nsame brain architectures. Not one brain, but the\nsame brain architecture. So what Einstein\ndid, what Mozart was able to do, what\nMarie Curie, and so on. And that, it's clear to me,\ntoday's systems don't have that. And then the other thing why I\nthink it's sort of overblown, the hype today on AGI, is\nthat our systems are not consistent enough\nto be considered to be fully general yet. They're quite general, So they\ncan do thousands of things. You've seen many\nimpressive things today. But every one of us have\nexperience with today's chatbots and assistants. You can easily,\nwithin a few minutes, find some obvious\nflaw with them-- some high school math thing\nthat it doesn't solve, some basic game it can't play. It's not very difficult to find\nthat those holes in the system. And for me, for something\nto be called AGI,",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_006",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 633.76,
    "timestamp_end": 767.01,
    "text": "find some obvious\nflaw with them-- some high school math thing\nthat it doesn't solve, some basic game it can't play. It's not very difficult to find\nthat those holes in the system. And for me, for something\nto be called AGI, it would need to be consistent,\nmuch more consistent across the board\nthan it is today. It should take a\ncouple of months for maybe a team of\nexperts to find a hole in it, an obvious hole in it. Whereas today, it takes an\nindividual minutes to find that. ALEX KANTROWITZ: Sergey,\nthis is a good one for you. Do you think that AGI\nis going to be reached by one company and\nit's game over, or could you see Google\nhaving AGI, OpenAI having AGI, Anthropic having\nAGI, China having AGI? SERGEY BRIN: Wow,\nthat's a great question. I mean, I guess I would suppose\nthat one company or country or entity will reach AGI first. Now, it is a little\nbit of a spectrum. It's not a completely\nprecise thing. So it's conceivable that there\nwill be more than one roughly in that range at the same time. After that, what happens? I mean, I think it's\nvery hard to foresee. But you could certainly\nimagine there's going to be multiple\nentities that come through. And in our AI space,\nwe've seen when we make a certain\nkind of advance, other companies are quick\nto follow and vice versa. When other companies\nmake certain advances, it's kind of a\nconstant leapfrog. So I do think there's\nan inspiration element that you see. And that would probably\nencourage more and more entities to cross that threshold. ALEX KANTROWITZ: Demis,\nwhat do you think? DEMIS HASSABIS: Well, I\nthink we probably do-- I think it is\nimportant for the field to agree on a definition of AGI. So maybe we should try\nand help that to coalesce. Assuming there is\none, there probably will be some organizations\nthat get there first. And I think it's important\nthat those first systems are built reliably and safely. And I think after that,\nif that's the case, we can imagine using them to\nshard off many systems that",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_007",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 751.95,
    "timestamp_end": 874.91,
    "text": "will be some organizations\nthat get there first. And I think it's important\nthat those first systems are built reliably and safely. And I think after that,\nif that's the case, we can imagine using them to\nshard off many systems that have safe architectures sort of\nbuilt provably underneath them. And then you could have\npersonal AGIs and all sorts of things happening. But it's quite difficult,\nas Sergey says, to predict, sort of see beyond the\nevent horizon to predict, what that's going to be like. ALEX KANTROWITZ: Right. So we talked a little bit\nabout the definition of AGI. And a lot of people have\nsaid AGI must be knowledge-- the intelligence of the brain. What about the\nintelligence of the heart? Demis, briefly, does. AI have to have emotion\nto be considered AGI? Can it have emotion? DEMIS HASSABIS: I think it will\nneed to understand emotion. I don't know if-- I think it will be a sort of\nalmost a design decision if we want it to mimic emotions. I don't see any reason\nwhy it couldn't in theory. But it might be\ndifferent, or it might be not necessary, or,\nin fact, not desirable for them to have the emotional\nreactions that we do as humans. So I think, again, it's a bit\nof an open question as we get closer to this AGI\ntime frame of events, which I think is more than\na 5 to 10-year time scale. So I think we have\na bit of time. Not much time, but\nsome time to research those kinds of questions. ALEX KANTROWITZ: When I think\nabout how the time frame might be shrunk, I wonder\nif it's going to be the creation of\nself-improving systems. And last week, I almost\nfell out of my chair reading this headline about something\ncalled AlphaEvolve, which is an AI that helps\ndesign better algorithms and even improve\nthe way LLMs train. So, Demis, are you trying to\ncause an intelligence explosion? DEMIS HASSABIS: No, not\nan uncontrolled one. Look, I think it's an\ninteresting first experiment. It's an amazing system. We've got a a great\nteam that's working on that, where it's interesting\nnow to start pairing",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_008",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 862.76,
    "timestamp_end": 997.9499999999999,
    "text": "DEMIS HASSABIS: No, not\nan uncontrolled one. Look, I think it's an\ninteresting first experiment. It's an amazing system. We've got a a great\nteam that's working on that, where it's interesting\nnow to start pairing other types of\ntechniques, in this case evolutionary\nprogramming techniques, with the latest foundation\nmodels, which are getting increasingly powerful. And I actually want to see in\nour exploratory work a lot more of these kind of\ncombinatorial systems and pairing different\napproaches together. And you're right, that\nis one of the things, the self-improvement--\nsomeone discovering a kind of self-improvement loop-- would be one way where things\nmight accelerate further than they're even going today. And we've seen it before\nwith our own work, with things like AlphaZero\nlearning chess, and Go, and any two-player\ngame from scratch within less than 24 hours,\nstarting from random with self-improving processes. So we know it's possible. But again, those are in\nquite limited game domains which are very well described. So the real world is far\nmessier and far more complex. So it remains to be seen\nif that type of approach can work in a more general way. ALEX KANTROWITZ: Sergey, we've\ntalked about some very powerful systems, and it's a race. It's a race to\ndevelop these systems. Is that why you\ncame back to Google? SERGEY BRIN: I mean, I think,\nas a computer scientist, it's a very unique\ntime in history. Honestly, anybody who's\na computer scientist should not be retired right now. They should be working on AI. That's what I would just say. I mean, there's just\nnever been a greater sort of problem, an opportunity,\na greater cusp of technology. So I wouldn't say it's\nbecause of the race. Although, we fully\nintend that Gemini will be the very first AGI. Let me clarify that. But to be immersed in this\nincredible technological revolution, it's unlike-- I went through\nthe web 1.0 thing. It was very exciting, and\nwe had mobile, we had this, we had that. But I think this is\nscientifically far more exciting.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_009",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 976.22,
    "timestamp_end": 1121.52,
    "text": "But to be immersed in this\nincredible technological revolution, it's unlike-- I went through\nthe web 1.0 thing. It was very exciting, and\nwe had mobile, we had this, we had that. But I think this is\nscientifically far more exciting. And I think ultimately\nthe impact on the world is going to be even greater. Inasmuch as the web and mobile\nphones have had a lot of impact, I think AI is going to be\nvastly more transformative. ALEX KANTROWITZ: So what\ndo you do day to day? [LAUGHTER] SERGEY BRIN: I think\nI torture people like Demis, who's amazing. By the way, he tolerated\nme crashing this fireside. I'm across the street\npretty much every day, and people who are working\non the key Gemini text models, on the pre-training, on\nthe post training, mostly those. I periodically delve into\nsome of the multimodal work-- Veo 3, as you've all seen. But I tend to be pretty deep\nin the technical details. And that's a luxury I\nreally enjoy, fortunately, because guys like Demis\nare minding the shop. And yeah, that's just where\nmy scientific interest is. It's deep in the algorithms\nand how they can evolve. ALEX KANTROWITZ: OK. Let's talk about the\nproducts a little bit, some that were\nintroduced recently. I just want to ask you a broad\nquestion about agents, Demis. Because when I look at\nother tech companies building agents, what we see in\nthe demos is usually something that's contextually aware,\nhas a disembodied voice, is often interacted-- you often interact\nwith it on a screen. When I see DeepMind\nand Google demos, oftentimes it's\nthrough the camera. It's very visual. There was an announcement\nabout smart glasses today. So talk a little bit about-- if that's the right\nread-- why Google is so interested in having an\nassistant or a companion that is something that sees\nthe world as you see it. DEMIS HASSABIS: Well,\nit's for several reasons. Several threads come together. So as we talked\nearlier, we've always been interested in agents. That's actually the heritage\nof DeepMind actually. We started with agent-based\nsystems in games.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_010",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 1109.872,
    "timestamp_end": 1213.9099999999999,
    "text": "DEMIS HASSABIS: Well,\nit's for several reasons. Several threads come together. So as we talked\nearlier, we've always been interested in agents. That's actually the heritage\nof DeepMind actually. We started with agent-based\nsystems in games. We are trying to\nbuild AGI, which is a full general intelligence. Clearly, that would\nhave to understand the physical environment, the\nphysical world around you. And two of the massive use\ncases for that, in my opinion, are a truly useful\nassistant that can come around with\nyou in your daily life and not just stuck on your\ncomputer or on one device. We want it to be useful in your\neveryday life for everything. And so it needs to come\naround you and understand your physical context. And then the other big\nthing is, I've always felt for robotics to\nwork, you sort of want what you saw with\nAstra on a robot. And I've always felt that\nthe bottleneck in robotics isn't so much the hardware--\nalthough, obviously there's many, many companies and\nworking on fantastic hardware, and we partner with\na lot of them-- but it's actually the\nsoftware intelligence that I think is always\nwhat's held robotics back. But I think we're in a\nreally exciting moment now, where finally, with\nthese latest versions, especially 2.5 Gemini and more\nthings that we're going to bring in-- this kind of Veo\ntechnology and other things-- I think we're going to have\nreally exciting algorithms to make robotics finally work\nand realize its potential. Which could be enormous. So And then in the\nend, AGI needs to be able to do all of those things. So for us-- and that's\nwhy you can see we always had this in mind--\nthat's why Gemini was built from the beginning,\neven the earliest versions, to be multimodal. And that made it\nharder at the start, because it's harder to make\nthings multimodal than just text only. But in the end, I\nthink we're reaping the benefits of\nthose decisions now-- and I see many of\nthe Gemini team here in the front row-- of\nthe correct decisions we made.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_011",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 1203.7,
    "timestamp_end": 1325.8100000000002,
    "text": "because it's harder to make\nthings multimodal than just text only. But in the end, I\nthink we're reaping the benefits of\nthose decisions now-- and I see many of\nthe Gemini team here in the front row-- of\nthe correct decisions we made. They were the hardest decisions,\nbut we made the right decisions. And now, you can see the\nfruits of that with all of what you've seen today actually. ALEX KANTROWITZ:\nSergey, I've been thinking about whether to ask\nyou a Google Glass question. SERGEY BRIN: Fire away. ALEX KANTROWITZ: What did you\nlearn from Glass that Google might be able to apply\ntoday now that it seems like smart glasses\nhave made a reappearance? SERGEY BRIN: Wow. Yeah, a great question. I learned a lot. I mean, that was-- I definitely feel like\nI made a lot of mistakes with Google Glass,\nI'll be honest. I am still a big believer\nin the form factor, so I'm glad that we have it now. And now it looks\nlike normal glasses. It doesn't have\nthe thing in front. I think there was a\ntechnology gap honestly. Now, in the AI world, the\nthings that these glasses can do to help you out without\nconstantly distracting you, that capability is much higher. There's also just I didn't\nknow anything about consumer electronics supply chains\nreally and how hard it would be to build that and\nhave it be at a reasonable price point. Managing all the\nmanufacturing and so forth. This time, we have\ngreat partners that are helping us build this. So that's another step forward. What else can I say? I do have to say I miss the\nairship with the wingsuiting skydivers for the demo. [LAUGHTER] SERGEY BRIN: Honestly, it would\nhave been even cooler here at Shoreline amphitheater\nthan it was up in Moscone back in the day. But maybe we'll have to-- we should probably polish\nthe product first this time. DEMIS HASSABIS: This time. We'll do it that way\naround this time. SERGEY BRIN: Make sure\nit's ready and available. And then we'll do\na really cool demo. So that's probably a smart move. DEMIS HASSABIS: Yeah. What I will say\nis, I mean, look,",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_012",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 1317.83,
    "timestamp_end": 1439.09,
    "text": "We'll do it that way\naround this time. SERGEY BRIN: Make sure\nit's ready and available. And then we'll do\na really cool demo. So that's probably a smart move. DEMIS HASSABIS: Yeah. What I will say\nis, I mean, look, we've got obviously an\nincredible history of glass devices and smart devices. We can bring all those\nlearnings to today. And I'm very excited about\nour new glasses, as you saw. But what I was always talking\nto our team and [INAUDIBLE] and the team about is that-- I mean, I don't know if\nSergey would agree, but-- I feel like the universal\nassistant is the killer app for smart glasses. And I think that's what's\ngoing to make it work. Apart from the fact that the\nhardware technology has also moved on and improved\na lot is I feel like this is the actual killer\napp, the natural killer app for it. ALEX KANTROWITZ: OK. Briefly, on video\ngeneration, I sat in the audience in the\nkeynote today and was fairly blown away by the\nlevel of improvement we've seen from these models. And you had filmmakers talking\nabout it in the presentation. I want to ask you,\nDemis, specifically about model quality. If the internet fills\nwith video that's been made with\nartificial intelligence, does that then go\nback into the training and lead to a\nlower quality model than if you were training just\nfrom human-generated content? DEMIS HASSABIS: Yeah. Look, we know there's\na lot of worries about this so-called\nmodel collapse. I mean, video is just one\nthing, but in any modality. Text as well. There's a few things\nto say about that. First of all, we're very\nrigorous with our data quality management and curation. We also, at least for all\nof our generative models, attach SynthID to them. So there's this invisible\nAI-made watermark that is very robust-- has held up now for a year, 18\nmonths, since we released it. And all of our\nimages and videos are embedded with this watermark. So we can detect, and\nwe're releasing tools to allow anyone to\ndetect, these watermarks and know that was an\nAI-generated image or video.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_013",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 1423.12,
    "timestamp_end": 1534.23,
    "text": "And all of our\nimages and videos are embedded with this watermark. So we can detect, and\nwe're releasing tools to allow anyone to\ndetect, these watermarks and know that was an\nAI-generated image or video. And of course that's\nimportant to combat deepfakes and misinformation, but\nit's also, of course, you could use that to filter\nout, if you wanted to, whatever was in your training data. So I don't actually see\nthat as a big problem. Eventually, we may\nhave video models that are so good you\ncould put them back into the loop as a source\nof additional data. Synthetic data, it's called. And there, you've just got to\nbe very careful that you're actually creating from\nthe same distribution that you're going\nto model, you're not distorting that distribution\nsomehow, the quality is high enough. We have some experience of this\nin a completely different way with things like AlphaFold,\nwhere there wasn't actually enough real experimental data\nto build the final AlphaFold, so we had to build an\nearlier version that then predicted about a\nmillion protein structures. And it had a confidence\nlevel on that, and we selected the top\n300,000-400,000 and put them back in the training data. So there's lots very\ncutting edge research to mix synthetic\ndata with real data. So there are also\nways of doing that. But on the terms of the\nvideo-generated stuff, you can just exclude\nit if you want to, at least with our own work,\nand hopefully other gen media companies follow suit and put\nrobust watermarks in also, obviously, first and\nforemost to combat deepfakes and misinformation. ALEX KANTROWITZ: OK,\nwe have four minutes. I got four questions left. We now move to the miscellaneous\npart of my questions. So let's see how many we\ncan get through in as fast as we can get through them. Let's go to Sergey\nwith this one. What does the web\nlook like in 10 years? SERGEY BRIN: What does the\nweb look like in 10 years? I mean-- DEMIS HASSABIS:\nYou've got one minute. SERGEY BRIN: Boy, I\nthink 10 years, because",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_014",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 1522.98,
    "timestamp_end": 1635.0919999999999,
    "text": "Let's go to Sergey\nwith this one. What does the web\nlook like in 10 years? SERGEY BRIN: What does the\nweb look like in 10 years? I mean-- DEMIS HASSABIS:\nYou've got one minute. SERGEY BRIN: Boy, I\nthink 10 years, because of the rate of progress in\nAI, is so far beyond anything we can see-- ALEX KANTROWITZ: Best guess. SERGEY BRIN: Not just the web. I mean, I don't know. I don't think we really\nknow what the world looks like in 10 years. ALEX KANTROWITZ: OK. Demis? DEMIS HASSABIS: Well, I\nthink that's a good answer. I do think the web\nin the nearer term is going to change quite a lot. If you think about\nan agent-first web, does it really need to-- it doesn't necessarily need to\nsee renders and things like we do as humans using the web. So I think things will be\npretty different in a few years. ALEX KANTROWITZ: OK. This is kind of an\nunder-over question. AGI before 2030 or after 2030? SERGEY BRIN: 2030. Boy, you really put\nit on that fine line. I'm going to say before. ALEX KANTROWITZ: Before? SERGEY BRIN: Yeah. ALEX KANTROWITZ: Demis. DEMIS HASSABIS: I'm just after. ALEX KANTROWITZ: Just after. OK. SERGEY BRIN: No pressure, Demis. DEMIS HASSABIS: Exactly. [LAUGHTER] DEMIS HASSABIS: I'll have to\ngo back and get working harder. ALEX KANTROWITZ: Is that-- SERGEY BRIN: I can ask for it. He needs to deliver it. DEMIS HASSABIS: Yeah, exactly. [LAUGHTER] SERGEY BRIN: Stop sandbagging. We need it next week. DEMIS HASSABIS: That's true. ALEX KANTROWITZ: I'll\ncome to the review. All right. So would you hire someone that\nused AI in their interview? Demis? DEMIS HASSABIS: Oh. In their interview? It depends how they used it. I think using today's\nmodels, tools, probably not. But I think that would be-- well, it depends how they\nwould use it actually I think is probably the answer. Sergey. SERGEY BRIN: I mean, I\nnever interviewed at all. So. [LAUGHTER] SERGEY BRIN: I don't know. I feel it would be hypocritical\nfor me to judge people exactly how they interview. DEMIS HASSABIS: Yeah, I\nhaven't either, actually. So [INAUDIBLE] on that.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_015",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 1622.46,
    "timestamp_end": 1740.3200000000002,
    "text": "SERGEY BRIN: I mean, I\nnever interviewed at all. So. [LAUGHTER] SERGEY BRIN: I don't know. I feel it would be hypocritical\nfor me to judge people exactly how they interview. DEMIS HASSABIS: Yeah, I\nhaven't either, actually. So [INAUDIBLE] on that. I've never done a job interview. SERGEY BRIN: Yeah. ALEX KANTROWITZ: OK. So Demis, I've been\nreading your tweets. You put a very\ninteresting tweet up where there was a\nprompt that created some sort of natural scene. DEMIS HASSABIS: Oh yeah. ALEX KANTROWITZ:\nHere was the tweet. \"Nature to simulation at the\npress of a button does make you wonder,\" with a\ncouple of emojis. And people ran with that and\nwrote some headlines saying \"Demis thinks we're\nin a simulation.\" Are we in a simulation? DEMIS HASSABIS: Not in the way\nthat Nick Bostrom and people talk about. I do think, though-- I don't think this\nis some kind of game, even though I wrote\na lot of games. I do think that ultimately\nunderlying physics is information theory. So I do think we're in a\ncomputational universe, but it's not just a\nstraightforward simulation. I can't answer\nyou in one minute. But I think the fact\nthat these systems are able to model real\nstructures in nature is quite interesting\nand telling. And I've been thinking\na lot about our work we've done with AlphaGo, and\nAlphaFold, and these types of systems. I've spoken a little about it. Maybe at some\npoint I'll write up a scientific paper\nabout what I think that really means in\nterms of what's actually going on here in reality. ALEX KANTROWITZ: Sergey,\nyou want to make a headline? [LAUGHTER] SERGEY BRIN: Well, I think that\nargument applies recursively, right? If we're in a simulation, then\nby the same argument, whatever beings are making\nthe simulation are themselves in a simulation\nfor roughly the same reasons, and so on and so forth. So I think you're going\nto have to either accept that we're in an infinite\nstack of simulations, or that there's got to be\nsome stopping criteria. ALEX KANTROWITZ: And\nwhat's your best guess?",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "Uh-7YX8tkxI__chunk_016",
    "schema_version": "canonical_v1",
    "video_id": "Uh-7YX8tkxI",
    "title": "Google I/O 2025 \u2013 Uh-7YX8tkxI",
    "timestamp_start": 1726.35,
    "timestamp_end": 1780.87,
    "text": "and so on and so forth. So I think you're going\nto have to either accept that we're in an infinite\nstack of simulations, or that there's got to be\nsome stopping criteria. ALEX KANTROWITZ: And\nwhat's your best guess? SERGEY BRIN: I think that we're\ntaking a very anthropocentric view when we say\nsimulation, in the sense that some kind of\nconscious being is running a simulation\nthat we are then in, and that they have\nsome kind of semblance of desire and consciousness\nthat's similar to us. I think that's where it\nkind of breaks down for me. So I just don't think\nthat we're really equipped to reason about one level\nup in the hierarchy. ALEX KANTROWITZ: OK. Well, Demis, Sergey,\nthank you so much. This has been such a\nfascinating conversation. SERGEY BRIN: Thank you. ALEX KANTROWITZ:\nAnd Thank you all. [APPLAUSE, MUSIC]",
    "source": "youtube",
    "speaker": "unknown"
  }
]