[
  {
    "id": "eIeJmYdYMQo__chunk_000",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 0.0,
    "timestamp_end": 144.54,
    "text": "[MUSIC PLAYING] DEVIN CHASANOFF: Hello, hello. MARK THOMPSON: We're\nso excited to be here. Welcome to our friends\nonline, and welcome to all of our friends in the room. This is \"What's new in Angular,\"\nor, as I originally called it-- I'm not kidding. This is true-- all\nthe fantastic updates coming to Angular\ndevelopers everywhere. But they made me change it. I wasn't too happy, but we'll\nstill keep this party going. Because you know what? Angular has had this incredible\nmoment, incredible moment in the developer world. We've been shipping features to\nimprove the developer experience for everyone. Listen, we've been\nworking hard to bring you the new features\nthat are so exciting and that enable you to build\nnew application experiences. And I'll be honest\nwith you, I get to do the work that\nI love, on a team that I love, with a community\nthat I love being a part of. So you all are fantastic. Give yourselves\naround of applause. [APPLAUSE] Yeah. It's OK to be happy\nfor yourselves. People are like, hmm. So we get to see the joy\nthat developers experience from improved APIs, better\nintegrations, and again, that overall better experience. Now, we take a lot\nof pride that we've worked so diligently to reduce\nthe pain points and making things easier for\nyou as developers. But say this next part with me. But wait, there's more. That's right. There's more. See, the Angular team is working\non something really special. And I bet that you\ncan guess what it is. It's the next version of\nAngular, Angular version 20. [APPLAUSE, CHEERS] So we're going to\nshare news with you across three different areas. We'll talk about new features. We'll talk about new\nintegrations and some of the other teams at Google\nthat we're partnering with. And we're also going to\ntalk about new directions. Where's the Angular team going. What other things are\nwe going to be doing? So to tell you all\nabout it, I need you to give me a just\nenormous round of applause to welcome Devin to the front. [APPLAUSE, CHEERS] DEVIN CHASANOFF:\nThanks, everybody.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_001",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 125.92,
    "timestamp_end": 281.53000000000003,
    "text": "What other things are\nwe going to be doing? So to tell you all\nabout it, I need you to give me a just\nenormous round of applause to welcome Devin to the front. [APPLAUSE, CHEERS] DEVIN CHASANOFF:\nThanks, everybody. What would a\nsession like this be without telling developers\nabout the one thing they care about most? That's right. You guessed it,\nintegration testing. I'm kidding. I'm kidding, new features. Oh, my God, they\nwere about to leave. It's OK, new features. And we know that building\napps that your users love goes hand in hand with the\ndelightful developer experience. I am just thrilled to\nshare what the Angular team has been up to lately. This team has been on\na roll, just cooking. And looking back at\nall this progress, I'm convinced that\nwhat I thought were groundbreaking\nfeatures at the time were really just paving\nthe way for even more incredible improvements. And today, I'm going to\ntell you the next part of the story for Angular\nSignals, server-side rendering, and authoring improvements,\nstarting with Angular Signals. When it comes to state\nmanagement in Angular, we've got a new mantra over\nhere on the Angular team. Work smarter, not harder,\nthanks to Angular Signals. Last year, we released\nsignals in developer preview. At a high level, Signals are\nAngular's modern approach to reactivity, a hassle free way\nto manage application state that reduces the amount of imperative\ncode that you have to write. As I like to put it, Angular's\nnew signal-based approach takes the management\nout of state management, which I love because when\nit comes to writing code, we're all really lazy. Wait, who wrote this? Busy, we're all really busy. We're not lazy. A signal is a wrapper around a\nvalue that notifies consumers when its value has changed. There are several\nvariations, including a signal, your basic\nsignal, as well as computed. Now, you might be\nasking yourself, hey, signals have\nbeen around since v17. Why are you bringing this\nup in a talk that was almost",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_002",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 265.52,
    "timestamp_end": 426.08,
    "text": "There are several\nvariations, including a signal, your basic\nsignal, as well as computed. Now, you might be\nasking yourself, hey, signals have\nbeen around since v17. Why are you bringing this\nup in a talk that was almost titled all the fantastic updates\ncoming to Angular developers? Well, for one,\nsignal and computed are now stable, which is a huge\nmilestone for the framework. And in v19, we\nintroduced linked signal. A linked signal is\na writable signal dependent on some other state. Another way to think about\nit, in its most basic form, is a computed signal that\nyou can set directly. But linked signal also\ngives you the ability to access prior\nstate, which makes it a game changer in\nthe signal ecosystem, as I'll illustrate\nin just a little bit. When you factor\nin linked signal, Angular Signals\ngive you the ability to create a reactive,\nself-managing graph of your application state,\nwhich means less development time, means fewer bugs, and\nsuperior maintainability. This really is a paradigm\nshift and a new way of thinking about state management. And a large part of\nthe reason for this, and I thought this\nwas so interesting, signals have no concept of time. Think about that. So rather than managing\napplication state in response to events that occur over time\nand tracking those events, you design a reactive\nsystem for a computing state at any given point in time. It's a subtle but\nreally important distinction that you begin\nto pick up on the more you work with signals. Oh, and did I mention\nlinked signal is being upgraded to stable in v20? Back in V19, we also introduced\na new experimental type of signal called a\nResource for reactively fetching asynchronous data. Or another way to think about\nit is a container for data fetched asynchronously. And as a reactive primitive,\nResource can update and respond to other signals\nchanging value, and it can notify downstream consumers\nwhen its value has changed. Let's look at an example\ninspired by an app I built earlier\nthis year that uses",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_003",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 401.55,
    "timestamp_end": 549.24,
    "text": "And as a reactive primitive,\nResource can update and respond to other signals\nchanging value, and it can notify downstream consumers\nwhen its value has changed. Let's look at an example\ninspired by an app I built earlier\nthis year that uses Gemini to create an interactive,\nchoose your own adventure graphic novel builder. And as a side note, if\nyou're interested in this, we open-sourced\nthe code so you can go to our angular/examples\nGitHub repository to check it out. Create your own graphic novels. And we also live-streamed\nus building this live, alongside our incredible\nAngular community. So you can check out our YouTube\nchannel if you want to see more. One of the app's features\nis generating images. Because, well, it wouldn't be a\ngraphic novel without graphics, now, would it? And in addition to\ndisplaying images, we also wanted to let users\nknow the loading status as well as give them the ability\nto retry failed requests. And great news, Resource handles\nall of this functionality right out of the box. Let's look at some code. Here we define a Resource. And it calls an\nasynchronous function to generate an\nimage using Gemini through the Genkit library. Resource has a\nparams field, which we've populated with a\nsignal called imgDescription. Any time this signal\nchanges, the Resource will run the\nasynchronous function defined in our loader field. The loader function takes\nthe params as a parameter, and here, you can see the\nloader function uses data in the params, our\nsignal, to call Genkit's asynchronous\nrunFlow method to generate an image with\nGemini and return the image URL. Resource exposes a\nstatus field as well as this convenient\nisLoading method. So in this case, we can show\na loading spinner to the user while the request is loading. And Resource also\nhas a reload method. So in the case of\nan error, which is represented by an empty\nstring in our application, we can show the user a piece\nof UI that, when clicked, retries the request. And finally, because the\nimage resource is effectively",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_004",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 534.73,
    "timestamp_end": 669.5200000000001,
    "text": "So in the case of\nan error, which is represented by an empty\nstring in our application, we can show the user a piece\nof UI that, when clicked, retries the request. And finally, because the\nimage resource is effectively just a container for our\nasynchronously fetched data, we can dynamically set\nthe image source, thereby rendering our beautiful image. And with that, we've created\nan entire image generation pipeline, complete with\nloading status, retry, and we did it all with a single\nresource and five lines of code. That's pretty cool. And, again, you can see\nthat we've done this by defining how application\nstate will be determined rather than writing code\nthat determines it ourselves. In addition to\ngenerating images, this app also generates\nthe story text for our graphic novel. Let's look at how we can combine\nResource with linked signal to accomplish our goal. MARK THOMPSON: Wait. Wait. Devin, did you generate\nthat story text with Gemini? Because I'm pretty sure that\nwe get bonuses every time we mention Gemini. DEVIN CHASANOFF: Oh,\nright, right, right. How's this? MARK THOMPSON: OK, better. DEVIN CHASANOFF: I know what\nyou're thinking, too subtle. Bam. How's that? MARK THOMPSON: Yeah,\nnow we're cooking. DEVIN CHASANOFF: All right. Anyhow, here you can\nsee our story resource that relies on changes\nto a user input signal to determine if we should\nfetch new story parts. And the function assigned\nto our loader field returns an array of\nthe latest three parts of our story, the latest three\npanels of our graphic novel. However, we're not just\ninterested in the latest three parts of the story. We want to show the\nusers the whole story. Because what's the fun in\ncreating a graphic novel if you can't just\nread the entire thing? And this is where linked\nsignal comes in handy. Using this signature\nof linkedSignal, we can reactively\nupdate its value to the result of the computation\nfield any time our source, in this case, our\nstoryResource.value, changes. And the computation field\nleverages the previous state",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_005",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 651.02,
    "timestamp_end": 814.2299999999999,
    "text": "Using this signature\nof linkedSignal, we can reactively\nupdate its value to the result of the computation\nfield any time our source, in this case, our\nstoryResource.value, changes. And the computation field\nleverages the previous state of our linkedSignal, appends\nthe most recent values returned from our server, and\ngives us the full story, all stored in this\nsingle linked signal. This simply wouldn't be\npossible with a standard signal. And Resource is such an\nintegral piece of the puzzle that we released several\nexperimental variations to streamline\ndeveloper workflows, starting with httpResource,\nwhich basically serves the same purpose as a resource,\nbut it's designed specifically for fetching data\nfrom HTTP endpoints. And this method signature\nis pretty slick. With httpResource,\nyou don't need to define params or\na loader function. Instead, you effectively\nembed your params directly into the request. So in this example, we'll make a\nrequest to the API user endpoint any time our current\nuser ID signal changes. And I also want to highlight a\nnew streaming resource pattern that we released in\nversion 19.2 that you can use to reactively\nupdate the UI as chunks are streamed from the server. With all of these improvements,\ndeveloper experience is only part of\nthe signal story. Because signals'\nfine-grained reactivity model can also provide\nsignificant performance benefits. For one, signals provide\nan efficient mechanism for computing state. And this gets even more\nexciting when we factor in our next major update. Introducing, Zoneless Angular. [CHEERS, APPLAUSE] Yeah. I should have stayed on that\nslide for an extra second. [LAUGHS] Well, historically, Angular\nhas relied on Zone.js to manage change detection\nand updating the DOM. And although signals\nprovide us with the ability to see exactly which pieces\nof UI need to be updated, Zone.js still runs\nchange detection in response to all\nbrowser events, not just the ones that result\nin updates to our templates. And that can lead to a\nlot of unnecessary checks.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_006",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 796.83,
    "timestamp_end": 948.07,
    "text": "to see exactly which pieces\nof UI need to be updated, Zone.js still runs\nchange detection in response to all\nbrowser events, not just the ones that result\nin updates to our templates. And that can lead to a\nlot of unnecessary checks. But not anymore,\nbecause in Angular v20, we'll be upgrading Zoneless\nAngular to developer preview so that developers can remove\nZone.js from their applications altogether. With this change, developers\nhave explicit control over when and how change\ndetection runs, for example, by running mark for\nchange or by leveraging signals' inherent\nknowledge of state changes. And they can trigger\nupdates more precisely, making Zoneless plus Signals\na powerful combination. Like I said, work\nsmarter, not harder. And while we're on the\ntopic of performance, let's shift our focus to\nserver-side rendering. SSR helps developers\nimprove website performance by rendering HTML on the server\nthat contains initial page state. And then once the HTML is\ndelivered to the browser, Angular initializes\nthe app and makes use of the data contained\nwithin the HTML. And since then, we've\nintroduced several pieces to the server-side\nrendering story. The first of which\nI'll be covering today is route-level\nrender mode config APIs to provide greater control\nwhen using hybrid rendering with server-side routing. Hybrid rendering has been\naround for a few years now and combines the benefits\nof server-side rendering, pre-rendering, also known\nas static site generation, as well as client-side rendering\nto optimize your Angular application. And in version 19, we\nintroduced the hybrid rendering config API to render different\nparts of your application using different strategies. And this new feature\ngives you complete control over your app's rendering to\nenhance performance, search engine optimization, and\noverall user experience, resulting in\ngreater flexibility, built-in internationalization,\nand a seamless dev server experience. That last one is actually\none of my favorites.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_007",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 929.68,
    "timestamp_end": 1081.3600000000001,
    "text": "over your app's rendering to\nenhance performance, search engine optimization, and\noverall user experience, resulting in\ngreater flexibility, built-in internationalization,\nand a seamless dev server experience. That last one is actually\none of my favorites. I just love being able to\nrun ng serve with an SSR app and get the full benefits\nof hot module replacement without having to rebuild. Oh, it's so nice, so nice. And we've got some\nnifty CLI commands that you can use\nto easily integrate this functionality into new\nand existing Angular apps. So once you're set up\nwith server routing, you can use the\nRender Mode field to declare which\nroutes should be rendered from the server\nas fully-populated HTML, pre-rendered at build time\nwith static-side generation, or rendered in the browser\nwith client-side rendering. There's even more to\nthe SSR story than that. In V19, we also introduced\nincremental hydration, which is why I've been taking\nthese small sips throughout. Stay hydrated, my friends. So, in case you\nneed a refresher, hydration is the\nprocess of restoring a server-side rendered\napplication in the client by doing things like reusing\nserver-rendered Dom structures, persisting application\nstate, and transferring application data\nthat was previously fetched on the server. Hydration improves\napplication performance by avoiding the extra work\nto recreate Dom nodes. With incremental\nhydration, you can leave sections of your\napplication dehydrated and incrementally trigger\ntheir hydration as needed. So this demo here shows\nincremental hydration in action for a\nserver-side rendered page. Components that are initially\ndehydrated are shown in gray. And at the beginning,\neverything besides that top bar is grayed out because we haven't\nyet downloaded the JavaScript. Then you can see the color\neffect applied as the user click event triggers hydration for\neach of these components. In Angular, we handle\nthis using defer blocks with hydrate triggers. As shown in this example, our\nlarge component isn't hydrated",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_008",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 1061.09,
    "timestamp_end": 1213.68,
    "text": "Then you can see the color\neffect applied as the user click event triggers hydration for\neach of these components. In Angular, we handle\nthis using defer blocks with hydrate triggers. As shown in this example, our\nlarge component isn't hydrated until after a user\ninteracts with it, and we can use a placeholder\nuntil that time comes. This is yet another opportunity\nfor Angular developers to improve application\nperformance by producing smaller initial bundles, while\nstill providing end users with an experience comparable\nto full application hydration. But wait, there's more. But wait, there's more. MARK THOMPSON: Devin,\ndid you just glitch? DEVIN CHASANOFF: No. Oh, no, no, I'm just\nreally, really excited about this next feature\nbecause in Angular V19, event replay is\nenabled by default. A common problem in server-side\nrendered apps in any framework is the gap that occurs between\na user event and the browser downloading and\nexecuting the code to actually handle that event. This visual demonstrates\nevent replay in action. So when the browser renders\nthe app for the first time, it hasn't yet downloaded\nthe JavaScript. And while it's downloading,\nthe user clicks the Add to Cart button four times. In the background,\nEvent Dispatch records all of these\nevents, and when the JavaScript responsible\nfor handling this event is done downloading,\nEvent Dispatch replays the events,\nresulting in all four items being added to our cart. Last May, we shared the\nEvent Dispatch library to address this\nexact use case, which you can enable by\nconfiguring your hydration provider with event replay. Shifting focus--\ndid anyone catch me breeze over hot module\nreplacement earlier? Well, let's take a\nsecond to talk about one of my favorite developer\nexperience improvements. Hot module replacement,\nor HMR, is a technique used by development servers to\navoid reloading the entire page when only part of an\napplication has changed so that you can see changes\nimmediately reflected in the browser. This can be extremely\nuseful when you're, say,",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_009",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 1198.82,
    "timestamp_end": 1363.86,
    "text": "used by development servers to\navoid reloading the entire page when only part of an\napplication has changed so that you can see changes\nimmediately reflected in the browser. This can be extremely\nuseful when you're, say, updating HTML or\nCSS, but you want to preserve the state of your\napplication in the browser. Next, I'm thrilled to\nshare some updates related to authoring in Angular. The future, it's standalone. We've gotten a ton\nof positive feedback from the community about\nstandalone components. In V14, we introduced\nstandalone in developer preview, and this made it possible\nto build applications without NgModules\nfor the first time. And since then, standalone\nhas been stabilized. And starting in V19, we made\nstandalone true the default for components,\npipes, and directives. In addition to making it easier\nto learn Angular and manage projects, standalone\ncomponents have paved the way for several new features, like\ndeferrable views, simplified route level lazy loading,\nas well as the directive composition API. In V19.2, we also introduced\nsupport for untagged literals and Angular templates, so you\ncan take advantage of string interpolation with\nliteral expression right in your templates. This could be useful for things\nlike improved readability, dynamic class naming and\nstyling, enhanced string manipulation, inline expression\nevaluation, and more. Here, we're able to cleanly\ninterpolate the call width property into the\nclass list of this div. And with this setup, we can\neasily change the column width by updating the\ncall width signal, while maintaining the\nlayout class styling. And finally, have you started\nusing Angular's new let syntax? We are listening\nto your feedback, and the new let syntax solves\none of the community's most upvoted issues by\nenabling developers to define and reuse variables\ninside Angular templates. Is it just me, or did we\nship a ton of features? From signals to SSR and\nauthoring improvements, we're working hard to\nship what you need. [APPLAUSE] Thanks.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_010",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 1342.66,
    "timestamp_end": 1504.48,
    "text": "to define and reuse variables\ninside Angular templates. Is it just me, or did we\nship a ton of features? From signals to SSR and\nauthoring improvements, we're working hard to\nship what you need. [APPLAUSE] Thanks. I'm relatively new to this team,\nhaving joined earlier this year. One of the most impressive\nthings I've noticed is how deeply\ninvested this team is in making Angular the best\nframework on the planet for building web applications. I mean, just look\nat how many features we've shipped since\nthis time last year. And we're not done yet. We're still listening. We're still building,\nand Angular V20 is coming to you next week. We can't wait to share even\nmore exciting updates with you. And with that-- [APPLAUSE] Give it up. With that, I'm going\nto pass it back to Mark to talk about some\nexciting new integrations. MARK THOMPSON:\nAll right, thanks, Devin, fantastic\nwork, so, so exciting. So let's talk new\nintegrations because software is built in components of\nsystems that work together with one goal, to help your\nusers accomplish tasks, whatever they've set out to do. So let's explore some new\nintegrations that will empower Angular developers everywhere. Now in version 20, we're going\nto update our testing story with a pretty meaningful\nchange because we're going to be adding support for a\nvery popular third-party testing framework. But before we talk\nabout that, let's talk about how we got here. You see, previously, we used\nKarma as our test runner, and we would export the results. Everyone used it, and people\nhad a pretty good time. But Karma was deprecated, so\nit put us in a unique position with a unique opportunity. Because did it mean\nthat we could finally see the end of unit testing? [CLAPPING] [LAUGHTER] Woo. OK, so the people who clapped,\nyou did not pass my test. [LAUGHTER] But I appreciate that energy. Well no, no, we\ndefinitely could not be at the end of unit\ntesting, but it put us in opportunity for a\nfresh start because here's what we thought about.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_011",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 1484.56,
    "timestamp_end": 1615.04,
    "text": "OK, so the people who clapped,\nyou did not pass my test. [LAUGHTER] But I appreciate that energy. Well no, no, we\ndefinitely could not be at the end of unit\ntesting, but it put us in opportunity for a\nfresh start because here's what we thought about. The external developer community\nhas advanced testing so much, and there are so many\noptions out there. So we figured that we should\ntry to find the best options to present to the\nAngular community to help you achieve\nyour best development. So as we're searching\nfor a long-term solution, we knew that we had to\nchoose something that hit three major points for us. First, there needed\nto be a well-lit path because here on\nthe Angular team, we're very proud of our work\nthat we've done to always bring the community along with\nus whenever we introduce a significant change. Then we're looking for\nstrong community support because we really want to\nmake Angular a wonderful place to build web apps. But we had to choose a tool that\nhas strong community support so that we will have\nconfidence that it will be a long-lasting solution. And finally, it has to\nimprove the overall developer experience. There are so many\noptions to consider, but if it doesn't increase the\noverall developer experience, then it's just not going to fit\nfor our wonderful community. Developers have two\noptions right now. You can test in a\nnode-based environment, or you can test in a\nbrowser-based environment. And so for node testing,\nnode-based testing, we have experimental\nJest support. And if you want to do\nsomething in the browser, we have experimental\nsupport for Web Test Runner. But then we thought,\ncould we find something that could\npotentially let you test in node environments\nand in the browsers? Because at a high level, that\nwould solve some problems that some development\nteams are facing right now. So with that in mind,\nwe are happy to announce that in Angular\nversion 20, we're introducing support for Vitest,\nexperimental support for Vitest. [CHEERING] Whoo-hoo.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_012",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 1599.35,
    "timestamp_end": 1729.095,
    "text": "that some development\nteams are facing right now. So with that in mind,\nwe are happy to announce that in Angular\nversion 20, we're introducing support for Vitest,\nexperimental support for Vitest. [CHEERING] Whoo-hoo. We knew you would\nbe happy about that. We're not surprised. We heard you. You've been telling us\nthis for a while, that you want us to try this out. So now, as a developer\nand an Angular developer, you have three things\nthat you can choose from. If you want to do\nnode testing, you have experimental Jest support\nfor browser, Web Test Runner, and then you can try for\nnode in-browser testing support for Vitest. But here's where your\nexpertise comes into play because we need your help. You see, we aren't going\nto support all three in the long term. It's not realistic. We would love for you to\ntry these out, give us some feedback,\nand then that will help us to be guided\ntoward the right solution for this amazing community. And we'll let you know\nin an upcoming release. All right, now let's\nturn our attention to what's probably the most\nimportant metric for developers, aside from revenue, and that\npeople really care about for their applications,\nperformance. So let's say it again. OK, let's turn our\nattention-- no, just kidding. The Angular team is\nsteadfast in our approach to delivering features to\nhelp you create performance applications, but we\nnoticed that while we had great tooling for\ndebugging in IDEs, if you want to capture profiling data,\nit was a little bit challenging. So let's take a look at a very\ncommon tool in Chrome DevTools. That's the Flame chart. Now, Flame charts are\nincredibly helpful, but even if we're\nlooking at this example, look at the number of\nentries that you find there. There's so much data,\nso much robust data. There is so much opportunity. But it can be hard\nto figure out which parts are your\napplication and then which parts are from a different\nlibrary or for something else. You know what we thought, I\nwish there was a better way. DEVIN CHASANOFF: Mark,\nthere is a better way.",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_013",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 1715.57,
    "timestamp_end": 1850.75,
    "text": "But it can be hard\nto figure out which parts are your\napplication and then which parts are from a different\nlibrary or for something else. You know what we thought, I\nwish there was a better way. DEVIN CHASANOFF: Mark,\nthere is a better way. MARK THOMPSON: Ah, yes,\nthere is, because we are so, so thrilled to announce that\nwe partnered with the Chrome DevTools team to create a\ncustom track in Chrome DevTools for Angular developers. [APPLAUSE] This is really cool. So in this new track, we\nsurface custom profiling data specific to you and your\nAngular applications in language that you are familiar\nwith and understand. You can quickly identify\nyour code from other code from maybe a\nthird-party library. Now the custom track\nis clearly labeled to give you notice at\na glance that you're viewing profile information\nspecific to Angular. But we didn't stop there. You see, the\nentries are actually color coded to give you even\nmore important information. For example, entry points like\nchange detection and component processing, those are blue, but\nthen, generated code is purple, and TypeScript code is green. Now the custom track is\neven more feature rich because you can click on\nany one of those entries and then get even more\ndata about that entry. So you're probably thinking,\nhow do I get started with this? First, you got to be\non Angular version 20, so be sure to update next\nweek when it comes out. Second, be on the latest\nversion of Chrome. Then when you head over\nto the profiling panel, you'll be able to see\nthis new custom track. Now we got to give a huge\nshout out and thank you to the Chrome DevTools team for\ntheir incredible partnership on this. By leveraging the power of the\nrecently introduced performance panel extensibility API,\nwe were able to create this awesome new feature. Now, this new integration\nwith Chrome DevTools will further empower\nyou to create applications and experiences\nthat your users will love. All right, if you like what\nwe've been talking about so far, let's hear some noise. [CHEERING]",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_014",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 1836.42,
    "timestamp_end": 1968.64,
    "text": "Now, this new integration\nwith Chrome DevTools will further empower\nyou to create applications and experiences\nthat your users will love. All right, if you like what\nwe've been talking about so far, let's hear some noise. [CHEERING] That's pretty good. That's pretty good. I love it, love it, love it. Let's talk about more. Let's talk about platforms. So as we continue our\nintegration story, there's another update\nwith the Google team that you may be familiar\nwith, and that's Firebase. Firebase has been really\non fire because they've had some amazing\nfeature releases and announcements like Genkit,\nFirebase App Hosting, and so much more. And our teams have\nbeen working together to improve the\ndeveloper experience. We all know about the data\nstory, but how can Firebase help you get your apps in\nfront of more users? Since Angular apps can\nnow be either client side only or full stack with SSR,\nyou need a deployment solution that works in both scenarios. Now, previously, you could\ndo something like this. You could use Cloud\nFunctions for Firebase to host your server-side\ncode, and then deploy your client-side\ncode using Firebase hosting. It worked, but it\nwasn't ideal, and we knew we could do a\nbetter experience. So we spent time working with\nthe engineers on Firebase to ensure that when you're using\nFirebase App Hosting to deploy your app, you have a\ntop-notch experience. Check this out. You can literally deploy\nyour Angular SSR app from the Firebase console\nwith a linked repository. And then those new rollouts\ncome as you add commits. And guess what? You get to leverage\nthe incredible power of the Firebase platform\nthat's powered by Google Cloud. But you could also create back\nends and configure deployments using the Firebase CLI. Now, no matter which\nroute you choose, the outcome is still the same. You can deploy\nupdates to production by leveraging\nautomatic rollouts, commit a change to\nthe configured branch, and then an automatic\nrollout will happen for you. So with Angular and\nFirebase App Hosting,",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_015",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 1956.76,
    "timestamp_end": 2099.7400000000002,
    "text": "You can deploy\nupdates to production by leveraging\nautomatic rollouts, commit a change to\nthe configured branch, and then an automatic\nrollout will happen for you. So with Angular and\nFirebase App Hosting, you are positioned to take that\nnew app that you've been working on and share it with the world. All right, let's talk\nabout new directions. I think you're really\ngoing to like this. We believe that AI has\nalready changed the way that we work as developers. And what's wild is that\nthese are early days. We don't even know how\nthings will evolve over time. There's so much opportunity, so\nmany cool things on the horizon, and it feels like it\nwas just yesterday that I was in this very\ntent, this very room, watching my colleagues\nAddy Osmani and David East give a talk about AI\ntooling and development workflows. It feels like I was in here. I was in here. Look at that head. That's me, the same person. And I had a front row\nseat to experience and to learn about all the\nnew tooling and AI features, just like you now\nhave a front row seat to learn about what's going\nto happen with Angular and AI. Listen, we understand AI is\ntoo transformational for us to just force it into Angular. So we've been thinking about\nmeaningful ways that we can do-- we can incorporate it. So it is with much excitement-- I'm so excited. I'm going to tell you. I'm going to tell you-- so much\nexcitement that we are launching the new AI portal,\nAngular.dev/AI. Now on Angular.dev/AI, you'll\nbe able to find guidance, best practices, coding\nexamples, recipes in AI. And guess what? This is just the first\nversion that we're launching, and we're going to continue\nto grow this resource. Here's an example of the type\nof recipe that you'll find on Angular.dev/AI. Now it's so common to want to\nsimulate that streaming effect when you're getting a response\nfrom an LLM, that typing effect. Well, what if I\ntold you that you could do that with\nAngular's resource API and a single primitive? Let's talk about it. First, using the\nresource API, there's",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_016",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 2083.09,
    "timestamp_end": 2236.1400000000003,
    "text": "when you're getting a response\nfrom an LLM, that typing effect. Well, what if I\ntold you that you could do that with\nAngular's resource API and a single primitive? Let's talk about it. First, using the\nresource API, there's a new property called\nstream that you can specify on the configuration object. Stream takes an async function. Now, from there, we define a\nsignal that when it's returned, it represents the\ndata being streamed. You can update that\nsignal just as you would using the normal API interface. And then this is just the\nclient-side implementation. Let's see, how do we link\nthis to an LLM response? So on the server side, this\nis just an express route. We're using the Gemini API\nto create a content stream. Then, you can\nstream the response to the client just using the\nwrite function on the response API. Now for the sake of this talk,\nwe've abbreviated this example, but I bet you could guess where\nyou can find the completed working code, Angular.dev/AI. I appreciate that energy. All right, listen, we have\nlinks to multi-hour development sessions led by Devin\nand myself walking you through integrations\nand implementations with tools like Firebase\nAI logic and Genkit. And we've also taken\ncare that while we are showing lots\nof Google AI tech, we also give guidance that is\nagnostic to our technology. Now we think you're really\ngoing to like what we've done, and we can't wait for\nyou all to check out this new part of Angular.dev. There is still so much\nmore awesome to come. Let's pass it back\nover to Devin. DEVIN CHASANOFF: All\nright, now that we've talked about new features,\nnew integrations, and of course, exciting\ndevelopments in AI, let's shift our\nfocus to the future and discuss Angular's roadmap. As we progress into\n2025, we remain hyper focused on two\nimportant things-- improving the Angular\ndeveloper experience and improving\nframework performance. In the long term, we're\nthinking about some game-changing improvements, such\nas selector-list components,",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_017",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 2220.2,
    "timestamp_end": 2371.41,
    "text": "hyper focused on two\nimportant things-- improving the Angular\ndeveloper experience and improving\nframework performance. In the long term, we're\nthinking about some game-changing improvements, such\nas selector-list components, which could pave the way for\neven more exciting new features like single-file components\nand even incremental adoption. Near term, we're\nfocused on delivering one of the community's most\nhighly requested feature to enhance the signal ecosystem. So in addition to\nthe signal types I've already talked\nabout today, we've also released different-- more\nsignals like input, output, model, and more. And yet, there's still one\npiece of the puzzle that's missing that I'm excited\nto share with you today, signal forms. [APPLAUSE] I knew you all would be\nexcited about this one. I'm not going to give\naway too much just yet, but I will say signal forms will\ngo a long way in rounding out the signal ecosystem, while\nalso making forms easier to work with in Angular. Today, we explored\nrecently released features, new integrations, and\nAngular's plan for the future. Through this discussion,\nI hope it's clear how hyper-focused we are\non developer experience and framework performance. However, I wanted\nto call out a theme that I noticed in looking\nat all these new features. Have you noticed that\neach of these features, they just seem to build on\neach other more and more? As we keep improving\nAngular, each change paves the way for new developer\nexperience and performance improvements. On the new features\nfront, I showed you how we made incredible\nprogress rounding out the signal ecosystem. And with Zoneless moving\nto developer preview, we can leverage signal's\ninherent state awareness to create highly\nperformant web apps. I also shared how we\nstrengthened Angular's SSR story with features like incremental\nhydration, a routing config APIs, and event replay. SSR, are you kidding me? This is awesome! And we've also been working\nhard to improve your developer experience by publishing\na variety of authoring",
    "source": "youtube",
    "speaker": "unknown"
  },
  {
    "id": "eIeJmYdYMQo__chunk_018",
    "schema_version": "canonical_v1",
    "video_id": "eIeJmYdYMQo",
    "title": "Google I/O 2025 \u2013 eIeJmYdYMQo",
    "timestamp_start": 2355.06,
    "timestamp_end": 2452.48,
    "text": "with features like incremental\nhydration, a routing config APIs, and event replay. SSR, are you kidding me? This is awesome! And we've also been working\nhard to improve your developer experience by publishing\na variety of authoring improvements, such as standalone\ncomponents, the new let syntax, and support for untagged\ntemplate-- untagged template literals. Mark shared a lot of exciting\nnew integration updates, including testing\nimprovements, a custom Angular track, and the Chrome\nperformance panel, and new ways to supercharge your\napps with the power of Firebase. Going forward, we're so\nexcited for you to check out Angular's new AI portal\nthat Mark shared, Angular.dev/AI so that you can\nlearn to create AI-powered apps that your users will love. To take advantage of all of\nthese new features we've covered today, upgrade to the\nlatest version of Angular, and don't forget to tune in to\nour Angular V20 developer event on May 29, at 9:00 AM\nPacific on YouTube. To everyone watching\nhere at Shoreline and watching the live\nstream, I got to tell you, don't sleep on this Angular team\nbecause the best is yet to come. Thank you all so much. [APPLAUSE] [MUSIC PLAYING]",
    "source": "youtube",
    "speaker": "unknown"
  }
]