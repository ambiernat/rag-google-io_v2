# ğŸ“„ RAG Retrieval, Evaluation & Production Deployment

## Project Overview

This project implements a **production-grade Retrieval-Augmented Generation (RAG) system** for Google I/O transcripts, supporting **dense, sparse, and hybrid retrieval**, **reranking**, **offline evaluation**, and a **deployed FastAPI service on AWS**.

It combines:

- Research-grade evaluation pipelines  
- Config-driven retrieval experimentation  
- A production-ready FastAPI API  
- Containerized cloud deployment using **AWS ECS + Fargate**

---

## ğŸ§  Core Capabilities

### Retrieval
- **Sparse retrieval** â€” BM25  
- **Dense retrieval** â€” SentenceTransformers embeddings  
- **Hybrid retrieval** â€” Dense + sparse fusion  
- **Vector store** â€” Qdrant  

### Reranking
- CrossEncoder-based reranking  
- Hyperparameter optimization (HPO)  
- Offline comparison of reranking strategies  

### Evaluation
- Recall@K, MRR, Precision@K  
- Offline A/B testing  
- Experiment tracking artifacts  

### Production
- FastAPI search service  
- Dockerized deployment  
- AWS ECS + Fargate  
- CloudWatch logging & monitoring  

---

## ğŸ“‚ Repository Structure (Actual)

```text
.
â”œâ”€â”€ api/                    # FastAPI app (production)
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ health.py
â”‚   â”‚   â””â”€â”€ search.py
â”‚   â”œâ”€â”€ models.py
â”‚   â””â”€â”€ schemas.py
â”‚
â”œâ”€â”€ retrieval/              # Retrieval logic
â”‚   â”œâ”€â”€ retrievers/
â”‚   â”‚   â”œâ”€â”€ retrieve_dense.py
â”‚   â”‚   â”œâ”€â”€ retrieve_sparse.py
â”‚   â”‚   â””â”€â”€ retrieve_hybrid.py
â”‚   â””â”€â”€ rerankers/
â”‚
â”œâ”€â”€ vector_store/           # Qdrant ingestion
â”‚   â”œâ”€â”€ ingest_dense.py
â”‚   â”œâ”€â”€ ingest_sparse.py
â”‚   â””â”€â”€ ingest_hybrid.py
â”‚
â”œâ”€â”€ evaluation/             # Offline evaluation
â”‚   â”œâ”€â”€ evaluate_dense.py
â”‚   â”œâ”€â”€ evaluate_sparse.py
â”‚   â”œâ”€â”€ evaluate_hybrid.py
â”‚   â””â”€â”€ evaluate_rerank_post_hpo.py
â”‚
â”œâ”€â”€ ingestion/              # Data ingestion & preprocessing
â”œâ”€â”€ data/                   # Raw, chunked, evaluation data
â”œâ”€â”€ qdrant_storage/         # Local Qdrant persistence (dev)
â”œâ”€â”€ tests/                  # Unit, integration & E2E tests
â”‚
â”œâ”€â”€ Dockerfile               # Production image
â”œâ”€â”€ docker-compose.yml       # Local dev stack
â”œâ”€â”€ docker-compose_prod.yml  # Production-like stack
â”œâ”€â”€ requirements.api.txt
â””â”€â”€ README.md

## âš™ï¸ Configuration

Configuration is **YAML-driven** across ingestion, retrieval, and evaluation.

**Example (`retrieval/config.yaml`):**

```yaml
qdrant:
  url: "http://localhost:6333"

collections:
  dense: "google-io-transcripts-dense"
  sparse: "google-io-transcripts-sparse"
  hybrid: "google-io-transcripts-hybrid"

retrieval:
  top_k: 5

## â–¶ï¸ Running Locally

### Docker (Recommended)

```bash
docker-compose up

## Services

### Example API Call

```bash
curl "http://localhost:8000/search?query=large language models&top_k=5"

## ğŸ§ª Offline Evaluation
### Run retrieval benchmarks locally:

```bash
python evaluation/evaluate_dense.py
python evaluation/evaluate_sparse.py
python evaluation/evaluate_hybrid.py
python evaluation/evaluate_rerank_post_hpo.py

### Outputs are written to:

```text
data/eval/results/

## ğŸ§  Testing

- **Unit tests** â€” retrievers, rerankers, embeddings  
- **Integration tests** â€” Qdrant connectivity, collections  
- **End-to-end tests** â€” FastAPI search endpoint  

Run all tests with:

```bash
pytest

## ğŸš€ Production Deployment (AWS)

This project is fully deployed on AWS using serverless containers.

### ğŸ³ Docker
Production Docker image bundles:

- FastAPI API

- Retrieval logic

- Model dependencies

**Image size**: ~550MB

## ğŸ“¦ ECR â€” Elastic Container Registry

- Private image registry

- Repository: fastapi-rag

**Image URI:**

```text
886166401772.dkr.ecr.us-east-1.amazonaws.com/fastapi-rag:latest

## ğŸ¯ ECS â€” Elastic Container Service

- **Cluster:** `rag-cluster`

### Task Definition
- **2 containers:**
  - FastAPI (3 GB RAM)
  - Qdrant (1 GB RAM)
- **Total resources:** 1 vCPU, 4 GB RAM

The ECS service keeps tasks alive (desired count configurable).

---

## âš¡ Fargate (Serverless Compute)

- No servers to manage  
- Pay only when tasks are running  

**Approximate cost at 1 running task:**
- ~$42/month  
- **$0 when desired count = 0**

---

## ğŸŒ Networking

- Default VPC  
- Public IP assigned per task  

**Security Group:**
- Inbound TCP 8000 (FastAPI)

**Example access:**
```text
http://<public-ip>:8000

## ğŸ“Š CloudWatch Logs

- **Log group:** `/ecs/rag-task`
- Separate streams per container:
  - `fastapi`
  - `qdrant`

**Used to debug:**
- Startup failures
- Missing models
- Misconfigured environment variables

---

## ğŸ” IAM

- **ECS Task Execution Role:**
  - Pull images from ECR
  - Write logs to CloudWatch
- CLI user created for deployments
- Principle of least privilege applied

---

## ğŸ’» EC2 (Temporary)

Used only once when CloudShell ran out of disk.

**Purpose:**
- Build Docker image
- Push image to ECR
- Instance terminated after use â†’ no ongoing cost

---

## ğŸ“ˆ Offline & Online Experimentation

### Offline
- Metric comparison across retrieval strategies
- Reranking effectiveness
- Hyperparameter optimization

### Online (Foundation in Place)
The API can be extended to log:
- Queries
- Retrieved documents
- Clicks
- Experiment group

This enables production **A/B testing**.

---

## ğŸ”® Future Enhancements

- Persistent Qdrant storage via EFS
- Autoscaling ECS services
- Authentication & rate limiting
- Query analytics dashboard
- Multi-language retrieval
- Online learning from user feedback

---

## âœ… Summary

This repository implements a **complete RAG system lifecycle**:

- âœ” Research & evaluation
- âœ” Retrieval + reranking experimentation
- âœ” Production FastAPI service
- âœ” Dockerized deployment
- âœ” Serverless AWS infrastructure

It bridges the gap between **ML research code** and **real-world production deployment**.